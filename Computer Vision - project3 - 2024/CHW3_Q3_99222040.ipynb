{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a467YiO6MeHX",
        "outputId": "88ac3ee9-1499-4f5b-e28a-2dd5621091da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, Dropout, Flatten, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError"
      ],
      "metadata": {
        "id": "6_0Jfk7hM4_n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_and_speeds(images_path, speeds_file):\n",
        "    images = sorted([os.path.join(images_path, img) for img in os.listdir(images_path) if img.endswith('.png')])\n",
        "    speeds = np.loadtxt(speeds_file)\n",
        "    return images, speeds"
      ],
      "metadata": {
        "id": "APaxrLbkNB-n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = \"/content/drive/MyDrive/assignment3 - computer vision - files/Q3/frames\"\n",
        "speeds_file = \"/content/drive/MyDrive/assignment3 - computer vision - files/Q3/train.txt\"\n",
        "images, speeds = load_images_and_speeds(images_path, speeds_file)"
      ],
      "metadata": {
        "id": "gWjb2ZOfNHTV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OpticalFlowDataset(tf.keras.utils.Sequence):\n",
        "    def __init__(self, img_paths, speeds, batch_size=8, shuffle=True):\n",
        "        self.img_paths = img_paths\n",
        "        self.speeds = speeds[1:]\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.img_paths) - 1) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_img_paths = [self.img_paths[i] for i in batch_indices]\n",
        "        batch_speeds = [self.speeds[i] for i in batch_indices]\n",
        "\n",
        "        batch_flow_hsv = []\n",
        "        batch_speed = []\n",
        "\n",
        "        for i in range(len(batch_img_paths) - 1):\n",
        "            img1_path = batch_img_paths[i]\n",
        "            img2_path = batch_img_paths[i + 1]\n",
        "\n",
        "            img1 = cv2.imread(img1_path)\n",
        "            img2 = cv2.imread(img2_path)\n",
        "\n",
        "            img1 = cv2.resize(img1, (128, 128))\n",
        "            img2 = cv2.resize(img2, (128, 128))\n",
        "\n",
        "            flow_hsv = self.compute_optical_flow_hsv(img1, img2)\n",
        "            flow_hsv = flow_hsv.astype(np.float32)\n",
        "\n",
        "            batch_flow_hsv.append(flow_hsv)\n",
        "            batch_speed.append(batch_speeds[i])\n",
        "\n",
        "        return np.array(batch_flow_hsv), np.array(batch_speed)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indices = np.arange(len(self.img_paths) - 1)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def compute_optical_flow_hsv(self, img1, img2):\n",
        "        prev_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "        gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "        hsv = np.zeros_like(img1)\n",
        "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "        hsv[..., 0] = ang * 180 / np.pi / 2\n",
        "        hsv[..., 1] = 255\n",
        "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "        hsv = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "        return hsv"
      ],
      "metadata": {
        "id": "Ap6s5D4yNOJm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(128, 128, 3))\n",
        "\n",
        "#first convolutional layer\n",
        "x = Conv2D(16, kernel_size=5, strides=2, padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = ReLU()(x)\n",
        "\n",
        "#second convolutional layer\n",
        "x = Conv2D(32, kernel_size=3, strides=2, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = ReLU()(x)\n",
        "\n",
        "#third convolutional layer\n",
        "x = Conv2D(64, kernel_size=3, strides=2, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = ReLU()(x)\n",
        "\n",
        "#fourth convolutional layer\n",
        "x = Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = ReLU()(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "print(f\"Feature map size before flattening: {x.shape}\")\n",
        "\n",
        "#fully connected layer\n",
        "x = Dense(128, activation='relu')(x)\n",
        "\n",
        "#dropout for regularization\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "outputs = Dense(1)(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4LezrnQNSVX",
        "outputId": "fb8cbbb8-75a7-47d6-cf10-4996720864b8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature map size before flattening: (None, 8192)\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 64, 64, 16)        1216      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 64, 64, 16)        64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 64, 64, 16)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        4640      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1048704   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1148001 (4.38 MB)\n",
            "Trainable params: 1147521 (4.38 MB)\n",
            "Non-trainable params: 480 (1.88 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = OpticalFlowDataset(images, speeds, batch_size=8, shuffle=True)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError())\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "#Keras data generator\n",
        "data_gen = tf.data.Dataset.from_generator(\n",
        "    lambda: dataset,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
        "    )\n",
        ")\n",
        "\n",
        "#prefetch data\n",
        "data_gen = data_gen.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "model.fit(data_gen, epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn03KMevNZC9",
        "outputId": "73345033-e579-4671-c9cd-1d8c6c34c48b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "2549/2549 [==============================] - 2929s 1s/step - loss: 61.8214\n",
            "Epoch 2/2\n",
            "2549/2549 [==============================] - 971s 381ms/step - loss: 48.0524\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7899519cd210>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}